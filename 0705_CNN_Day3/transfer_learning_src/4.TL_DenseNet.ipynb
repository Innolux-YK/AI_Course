{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure環境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用國網環境，請確定已經下載好Simpson dataset\n",
    "# 預設資料集就是與此notebook檔案同樣的路徑底下\n",
    "data_dir = './'\n",
    "data_path = os.path.join(data_dir, 'simpsons_dataset/')\n",
    "\n",
    "# 先確定好模型儲存的路徑，預設儲存在與notebook檔案同樣的路徑底下\n",
    "\n",
    "#要改模型儲存路徑\n",
    "model_dir = './model-logs/DenseNet'\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# save model\n",
    "modelfiles = model_dir + '/basic_model-best-model.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOmXeTNwOzr4"
   },
   "source": [
    "# 一、Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9wxI-4lWzYn"
   },
   "source": [
    "## 1. 將圖片路徑以及標籤個存取在陣列裡面\n",
    "`x_data_list` : 圖片的路徑\n",
    "\n",
    "`y_data_lsit` : 圖片的標籤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FmfmBDP2O8jz"
   },
   "outputs": [],
   "source": [
    "x_data_list = [] #圖片的路徑\n",
    "y_data_list = [] #圖片的標籤\n",
    "\n",
    "# data_path = './simpsons_dataset'\n",
    "# os.path.join(data_path,dir) = './simpsons_dataset/abraham_grampa_simpson'\n",
    "\n",
    "for dir in os.listdir(data_path): \n",
    "    for img in os.listdir(os.path.join(data_path,dir)): \n",
    "        x_data_list.append(os.path.join(data_path,dir,img))\n",
    "        y_data_list.append(dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KoUHS3hXDXU"
   },
   "source": [
    "## 2. List to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 4359,
     "status": "ok",
     "timestamp": 1625125295058,
     "user": {
      "displayName": "Chris Liao",
      "photoUrl": "",
      "userId": "00946619667757242614"
     },
     "user_tz": -480
    },
    "id": "lWe8VneMO8l6",
    "outputId": "0e323a96-f56f-4e9e-f068-0c19074639f6"
   },
   "outputs": [],
   "source": [
    "data_list = pd.DataFrame({})\n",
    "data_list['img_path'] = x_data_list\n",
    "data_list['label'] = y_data_list\n",
    "data_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdDJmVvFTCKc"
   },
   "source": [
    "# 二、資料預處理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZnKo4k7WX8J3"
   },
   "source": [
    "## 1. Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1625125295058,
     "user": {
      "displayName": "Chris Liao",
      "photoUrl": "",
      "userId": "00946619667757242614"
     },
     "user_tz": -480
    },
    "id": "JnJ5fdioTEn8",
    "outputId": "7df96a5b-bbd0-4461-aa77-7ff9532436e7"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_list, test_list = train_test_split(data_list,\n",
    "                                         test_size=0.2,\n",
    "                                         random_state=42,\n",
    "                                         #按比例分配，如Labela, Labelb的比例是2:1, 則train and test的 Labela, Labelb的比例都會是2:1\n",
    "                                         stratify=data_list['label'].values,\n",
    "                                         shuffle = True)\n",
    "print(len(train_list),len(test_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train = []; y_Train = []\n",
    "X_Test = []; y_Test = []\n",
    "\n",
    "for i in range(len(train_list)):\n",
    "    X_Train.append(train_list.iloc[i].img_path)\n",
    "    y_Train.append(train_list.iloc[i].label)\n",
    "    \n",
    "for i in range(len(test_list)):\n",
    "    X_Test.append(test_list.iloc[i].img_path)\n",
    "    y_Test.append(test_list.iloc[i].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m3vE3Zy-VndW"
   },
   "outputs": [],
   "source": [
    "print(X_Train[:10])\n",
    "print(y_Train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#隨機查看圖片\n",
    "import random\n",
    "def ShowImage(images,labels,total=10): #圖片，標籤，預測標籤，總共顯示張數\n",
    "    plt.gcf().set_size_inches(18, 20)\n",
    "    if total >=25:\n",
    "        total = 25\n",
    "    for i in range(0,total):\n",
    "        num = random.randint(0,len(labels)-1)\n",
    "        img_show = plt.subplot(5, 5, i+1)\n",
    "        Img = cv2.imread(images[num])\n",
    "        img_show.imshow(Img[:,:,::-1])\n",
    "        title = \"label = \"+str(labels[num])\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "ShowImage(X_Train,y_Train,total=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 標籤的Number Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {}\n",
    "\n",
    "Count = 0\n",
    "for i in range(len(data_list)):\n",
    "    if data_list.iloc[i].label in label_dict:\n",
    "        continue\n",
    "    else:\n",
    "        label_dict[data_list.iloc[i].label] = Count\n",
    "        Count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelreverse = {v: k for k, v in label_dict.items()}\n",
    "labelreverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PeNIpzYHYBo2"
   },
   "source": [
    "## 3. 建立預處理功能以及建立data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/vision/main/models/generated/torchvision.models.densenet121.html#torchvision.models.densenet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WEnHePMSVBDn"
   },
   "outputs": [],
   "source": [
    "# 訓練集的預處理及資料擴增\n",
    "# resize的default為PIL.Image.BILINEAR\n",
    "preprocess_train = transforms.Compose([transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                                       transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                       transforms.Resize((image_shape,image_shape)),\n",
    "                                       transforms.RandomAffine(degrees=(-30,30), translate=(0.1, 0.1), scale=(0.9, 1.5), shear=(0,0)),])\n",
    "                                       #transforms.RandomResizedCrop((image_shape,image_shape))])\n",
    "\n",
    "# 測試集的預處理\n",
    "preprocess_test = transforms.Compose([transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                                      transforms.Resize((image_shape,image_shape)),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_loader(path, preprocess_function):\n",
    "    # 使用cv2讀取圖片\n",
    "    img_pil = cv2.imread(path)\n",
    "    # 將BGR 轉換成 RGB\n",
    "    img_pil = cv2.cvtColor(img_pil, cv2.COLOR_BGR2RGB)\n",
    "    # 將前面的預處理方式加入圖片中\n",
    "    img_tensor = preprocess_function(img_pil)\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Generator(Dataset):\n",
    "    def __init__(self, image_file, image_label, label_dict, pre_fn, loader = default_loader):\n",
    "        \n",
    "        self.images = image_file      # 圖片路徑的陣列\n",
    "        self.target = image_label     # 圖片標籤的陣列\n",
    "        self.label_dict = label_dict  # 如：{'dogs': 0, 'cats': 1}\n",
    "        self.pre_fn = pre_fn          # 資料預處理\n",
    "        self.loader = loader          # 讀圖片的function\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fn = self.images[index]      # 圖片路徑\n",
    "        \n",
    "        img = self.loader(path = fn, # 圖片讀取以及預處理後的結果，輸入模型用\n",
    "                          preprocess_function = self.pre_fn)\n",
    "        \n",
    "        target = self.label_dict[self.target[index]] # 圖片標籤, 並轉換成數字\n",
    "        \n",
    "        return img,target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)     # 回傳資料集數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 先呼叫我們寫好的Custom_Generator, 將圖片的路徑陣列、圖片的標籤陣列以及預處理功能放入裡面\n",
    "train_data  = Custom_Generator(image_file = X_Train, \n",
    "                               image_label = y_Train, \n",
    "                               label_dict = label_dict,\n",
    "                               pre_fn = preprocess_train)\n",
    "\n",
    "# 2. 呼叫pytorch的DataLoader來做批次動作，模型的輸入\n",
    "trainloader = DataLoader(train_data, batch_size=32,shuffle=True)\n",
    "\n",
    "# 1. 先呼叫我們寫好的Custom_Generator, 將圖片的路徑陣列、圖片的標籤陣列以及預處理功能放入裡面\n",
    "test_data  = Custom_Generator(image_file = X_Test, \n",
    "                              image_label = y_Test, \n",
    "                              label_dict = label_dict,\n",
    "                              pre_fn = preprocess_test)\n",
    "\n",
    "# 2. 呼叫pytorch的DataLoader來做批次動作，模型的輸入\n",
    "testloader = DataLoader(test_data, batch_size=32,shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2KnXwOaGXhU4"
   },
   "source": [
    "# 三、載入預訓練模型\n",
    "Use `densenet121` for Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HRCu1egYg1R"
   },
   "source": [
    "## 1. 讀入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = models.densenet121(pretrained=True)\n",
    "cnn_model.classifier = nn.Sequential(nn.Linear(in_features = 1024, out_features = 128),  #512 * 7 * 7不能改變\n",
    "                                     nn.ReLU(True),\n",
    "                                     nn.Dropout(),\n",
    "                                     nn.Linear(in_features = 128, out_features = len(labelreverse)),)\n",
    "cnn_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 決定要Fine tune Freeze的layer(如果不Freezing可以略過這一步)\n",
    "這個要判斷今天的資料集狀況再決定是否要對預訓練模型的layer做Freezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以先查看所有layers的名稱\n",
    "for name, param in cnn_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "        \n",
    "print(cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 再決定要layer freeze哪幾層\n",
    "# for name, param in cnn_model.named_parameters():\n",
    "#     if param.requires_grad and name == '':\n",
    "#         break\n",
    "#     elif param.requires_grad:\n",
    "#         print(name)\n",
    "#         param.requires_grad = False\n",
    "        \n",
    "cnn_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IV7FHvQ4amPi"
   },
   "source": [
    "## 2. 決定 Loss function 、Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H-YYGWkgahkH"
   },
   "outputs": [],
   "source": [
    "# 選用Adam為optimizer\n",
    "# Parameters\n",
    "# pytorch的CrossEntropyLoss在計算時，會以softmax的輸出作為最後的結果\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.0001\n",
    "epochs = 10\n",
    "warm_up_epochs = 1\n",
    "\n",
    "#optimizer_cnn = optim.SGD(cnn_model.parameters(), lr=lr, momentum=0.9)\n",
    "optimizer_cnn = optim.Adam(cnn_model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_cnn, \n",
    "                                                       mode='min', \n",
    "                                                       factor=0.1, \n",
    "                                                       patience=3, \n",
    "                                                       verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dTBCLd40Y4Y0"
   },
   "source": [
    "## 4. 開始訓練囉！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrintLogMessage(Now_epoch, Total_epoch, Now_itr, Total_itr, loss, acc, train = True, flush = False):\n",
    "    if train == True and flush == True:\n",
    "        print('[%02d/%02d, %d/%d] loss: %.3f, acc: %.3f' % (Now_epoch, Total_epoch, Now_itr, Total_itr, loss,acc),end = \"\")\n",
    "        print(\"\\r\", end=\"\", flush=True)\n",
    "    elif train == True and flush == False:\n",
    "        print('[%02d/%02d, %d/%d] loss: %.3f, acc: %.3f' % (Now_epoch, Total_epoch, Now_itr, Total_itr, loss,acc),end = \"\")\n",
    "    elif train == False:\n",
    "        print(', test_loss: %.3f, test_acc: %.3f' % (loss,acc))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtuWRBfSWXuf"
   },
   "outputs": [],
   "source": [
    "# 訓練過程\n",
    "# len(trainLoader) : 訓練集總共的資料量 / batch\n",
    "# len(trainLoader.dataset) : 訓練集總共的資料量\n",
    "\n",
    "Best_Acc = 0\n",
    "cnn_loss_history = []\n",
    "cnn_acc_history = []\n",
    "\n",
    "cnn_valloss_history = []\n",
    "cnn_valacc_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 訓練階段\n",
    "    cnn_model.train()\n",
    "    running_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "\n",
    "    for times, data_train in enumerate(trainloader, 0):\n",
    "        # batch data input\n",
    "        inputs, labels = data_train\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer_cnn.zero_grad()\n",
    "\n",
    "        # model Feedforward\n",
    "        output_train = cnn_model(inputs)\n",
    "        # Feed forward loss result\n",
    "        loss = criterion(output_train, labels)\n",
    "        \n",
    "        # backward update\n",
    "        loss.backward()\n",
    "        \n",
    "        # optimize\n",
    "        optimizer_cnn.step()\n",
    "\n",
    "        # Compute loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(output_train.data, 1)\n",
    "        total += labels.size(0)\n",
    "        accuracy += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Print log message\n",
    "        PrintLogMessage(Now_epoch = epoch+1, \n",
    "                        Total_epoch = epochs, \n",
    "                        Now_itr = times+1, \n",
    "                        Total_itr = len(trainloader), \n",
    "                        loss = running_loss/(times+1), \n",
    "                        acc = accuracy / total, \n",
    "                        train = True, \n",
    "                        flush = True)\n",
    "        if times+1 == len(trainloader):\n",
    "            # Print log message\n",
    "            PrintLogMessage(Now_epoch = epoch+1, \n",
    "                            Total_epoch = epochs, \n",
    "                            Now_itr = times+1, \n",
    "                            Total_itr = len(trainloader), \n",
    "                            loss = running_loss/(times+1), \n",
    "                            acc = accuracy / total, \n",
    "                            train = True, \n",
    "                            flush = False)\n",
    "            cnn_loss_history.append(running_loss/len(trainloader))\n",
    "            cnn_acc_history.append(accuracy / total)\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # 測試階段\n",
    "    cnn_model.eval()\n",
    "    test_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    with torch.no_grad(): # disable gradient calculation for efficiency\n",
    "        for times, data_test in enumerate(testloader, 0):\n",
    "            # batch data input\n",
    "            inputs, labels = data_test\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # model predict    \n",
    "            output_test = cnn_model(inputs)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss_t = criterion(output_test, labels)\n",
    "            test_loss += loss_t.item()\n",
    "            \n",
    "            # Compute accuracy\n",
    "            _, predicted = torch.max(output_test.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "            \n",
    "            if times+1 == len(testloader):\n",
    "                scheduler.step(test_loss / len(testloader))\n",
    "                # Print log message\n",
    "                PrintLogMessage(Now_epoch = epoch+1, \n",
    "                                Total_epoch = epochs, \n",
    "                                Now_itr = times+1, \n",
    "                                Total_itr = len(testloader), \n",
    "                                loss = test_loss/(times+1), \n",
    "                                acc = accuracy / total, \n",
    "                                train = False, \n",
    "                                flush = False)\n",
    "                if (accuracy / total) > Best_Acc:\n",
    "                    Best_Acc = (accuracy / total)\n",
    "                    torch.save(cnn_model, modelfiles)\n",
    "                    print(\"Save Model!\")\n",
    "                \n",
    "                cnn_valloss_history.append(test_loss / len(testloader))\n",
    "                cnn_valacc_history.append(accuracy / total)\n",
    "                test_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-9x8mQLe_Qa"
   },
   "source": [
    "# 四、查看模型訓練結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "executionInfo": {
     "elapsed": 744,
     "status": "ok",
     "timestamp": 1623894716739,
     "user": {
      "displayName": "Chris Liao",
      "photoUrl": "",
      "userId": "04941070556500376940"
     },
     "user_tz": -480
    },
    "id": "H1pi2iKre-1X",
    "outputId": "9c6a08bd-dea1-4740-cc52-1064e30d9c5b"
   },
   "outputs": [],
   "source": [
    "def Show_Train_flow(train_cnnmodel, test_cnnmodel, Show = 'loss', Title='Training accuracy comparision'):\n",
    "    plt.plot(train_cnnmodel)\n",
    "    plt.plot(test_cnnmodel)\n",
    "    plt.title(Title)\n",
    "    plt.ylabel(Show)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train','test'])\n",
    "    plt.show()\n",
    "    \n",
    "Show_Train_flow(cnn_loss_history, cnn_valloss_history, Show = 'loss', Title='cnn loss comparision')\n",
    "Show_Train_flow(cnn_acc_history, cnn_valacc_history, Show = 'acc', Title='cnn acc comparision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JG9VMdwGkh9y"
   },
   "source": [
    "# 五、測試模型\n",
    "在訓練好模型後，我們一定會拿測試集來測試一下我們訓練模型的好壞\n",
    "\n",
    "現在就是要使用`kaggle_simpson_testset`來進行預測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TG1pptsIJT9e"
   },
   "source": [
    "## 1. 如果今天想要使用訓練好的模型的話，可以直接load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eFeoEzHeJEP8"
   },
   "outputs": [],
   "source": [
    "cnn_model = torch.load(modelfiles)\n",
    "cnn_model.to(device)\n",
    "# Set model to eval mode\n",
    "cnn_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sB-ym5cHZZkd"
   },
   "source": [
    "## 2. 將預測的資料集讀取下來，並轉換成dataframe形式\n",
    "** 會全部先設定`class`為1是因為我們不知道標籤，所以先預設為1 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#讀取圖片與 Label\n",
    "testing_dir_path = os.path.join(data_dir, 'kaggle_simpson_testset/predict')\n",
    "all_file = os.listdir(os.path.join(data_dir, 'kaggle_simpson_testset/predict'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 302,
     "status": "ok",
     "timestamp": 1625125941268,
     "user": {
      "displayName": "Chris Liao",
      "photoUrl": "",
      "userId": "00946619667757242614"
     },
     "user_tz": -480
    },
    "id": "nQrNdkKWkh9y",
    "outputId": "c39ea4e1-3601-43f9-ad0b-ec0bf4bf6360"
   },
   "outputs": [],
   "source": [
    "# 有原因的\n",
    "all_file.sort()\n",
    "test_df = pd.DataFrame({'file_path':all_file,'class':1}) \n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghMiqErWZwXf"
   },
   "source": [
    "## 3. 將測試集讀入到keras data generator\n",
    "因為沒有答案，所以務必將`class_mode`設定為`None`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_output = nn.Softmax(dim=1)\n",
    "\n",
    "predict_output = []\n",
    "\n",
    "for i in tqdm(range(len(test_df)),position=0):\n",
    "    Img = cv2.imread(os.path.join(testing_dir_path,test_df.iloc[i].file_path))\n",
    "    Img = cv2.cvtColor(Img, cv2.COLOR_BGR2RGB)\n",
    "    ImgTest = preprocess_test(Img)    # 將圖片轉換成torch tensor(才能丟入模型進行預測)\n",
    "    ImgTest = torch.unsqueeze(ImgTest, 0)\n",
    "    ImgTest = ImgTest.to(device)          # to gpu mode\n",
    "    Result = cnn_model(ImgTest)           # Predict images\n",
    "    sm_Result = softmax_output(Result)    # softmax output\n",
    "    \n",
    "    sm_Result = sm_Result.data.cpu().numpy()\n",
    "    predict_output.append(sm_Result[0].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelreverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_label = [] # 設定一個將softmax結果轉換成標籤的陣列\n",
    "\n",
    "for i in range(len(predict_output)):\n",
    "    y_pred_label.append(labelreverse[predict_output[i]])\n",
    "    \n",
    "y_pred_label = np.array(y_pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1625126103411,
     "user": {
      "displayName": "Chris Liao",
      "photoUrl": "",
      "userId": "00946619667757242614"
     },
     "user_tz": -480
    },
    "id": "0hEZti0ckh9z",
    "outputId": "2dd3ba12-6982-41e9-bc82-65e5d3325fb3"
   },
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({'file_path':all_file,'pred':y_pred_label})\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ok9yuAJLjzkx"
   },
   "source": [
    "# 六、評估模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4aym8ZFkDiV"
   },
   "source": [
    "## 1. 讀取正確答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_ans = pd.read_csv(data_dir + \"ans.csv\")\n",
    "correct_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1625126130162,
     "user": {
      "displayName": "Chris Liao",
      "photoUrl": "",
      "userId": "00946619667757242614"
     },
     "user_tz": -480
    },
    "id": "E1JXUmyLj4Kk",
    "outputId": "0e37607f-8420-4638-d92e-6c2b62e30b65"
   },
   "outputs": [],
   "source": [
    "correct_ans = correct_ans.sort_values(by=['file'])\n",
    "correct_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0AjR8wnlv3G"
   },
   "source": [
    "## 2. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h7YiIbXeWgvx"
   },
   "outputs": [],
   "source": [
    "# 將預測標籤與實際標籤儲存進陣列裡面\n",
    "y_predict = [];y_TrueLabel=[]\n",
    "\n",
    "y_TrueLabel = correct_ans['class'].values\n",
    "y_predict = test_df['pred'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1625126289312,
     "user": {
      "displayName": "Chris Liao",
      "photoUrl": "",
      "userId": "00946619667757242614"
     },
     "user_tz": -480
    },
    "id": "acEaGfA9lEX1",
    "outputId": "1b2b5ce9-178a-447e-9d11-d020da8d8ede"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_TrueLabel = np.asarray(y_TrueLabel)\n",
    "y_predict = np.asarray(y_predict)\n",
    "print(classification_report(y_TrueLabel, y_predict, digits = 3))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 707
    },
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1625126330329,
     "user": {
      "displayName": "Chris Liao",
      "photoUrl": "",
      "userId": "00946619667757242614"
     },
     "user_tz": -480
    },
    "id": "o3CWhUORkh91",
    "outputId": "6a664436-f321-4a03-a7fd-7e694f88b0f6"
   },
   "outputs": [],
   "source": [
    "display(pd.crosstab(y_TrueLabel, y_predict, rownames=[\"True\"], colnames=[\"Predict\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KKq67n8NrGBc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "VGG16.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
