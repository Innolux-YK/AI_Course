{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6e5481c",
   "metadata": {},
   "source": [
    "# 3.learning_rate.ipynb 說明\n",
    "本 notebook 主要教學如何在影像分類任務中實作與比較多種學習率（Learning Rate）調整策略。內容重點如下：\n",
    "1. **學習率調整理論簡介**：介紹學習率對深度學習訓練的影響，以及常見的調整方法（固定、StepLR、ReduceLROnPlateau、CosineWarmup等）。\n",
    "2. **PyTorch 實作**：示範如何用 PyTorch 實作各種學習率調整策略，並整合到訓練流程中。\n",
    "3. **資料前處理與載入**：包含資料集的下載、前處理（如正規化、資料增強）與 DataLoader 建立。\n",
    "4. **模型訓練與驗證**：設計訓練流程，記錄 loss 與 accuracy，並可視覺化訓練過程。\n",
    "5. **學習率策略效果觀察**：比較不同學習率策略下的訓練結果，觀察其對模型表現的影響。\n",
    "本 notebook 適合用於理解現代深度學習中的學習率調整技巧，並學習如何將多種策略實際應用於影像分類專案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07f2209",
   "metadata": {
    "executionInfo": {
     "elapsed": 12641,
     "status": "ok",
     "timestamp": 1742277463128,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "d07f2209"
   },
   "outputs": [],
   "source": [
    "# import package\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2e2cdb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1742277463142,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "2d2e2cdb",
    "outputId": "c9a03e74-c29a-49d0-93f2-ed37c0437879"
   },
   "outputs": [],
   "source": [
    "# device add gpu\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")       # 使用Nvidia 顯卡\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")# 使用mac m1 晶片\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd41c87c",
   "metadata": {
    "id": "bd41c87c"
   },
   "source": [
    "# 一、資料讀取與處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d5a0a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "executionInfo": {
     "elapsed": 7786,
     "status": "ok",
     "timestamp": 1742277488826,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "07d5a0a4",
    "outputId": "37c4c14b-17f1-408f-9a6d-1816dd6e1a66"
   },
   "outputs": [],
   "source": [
    "# import gdown\n",
    "\n",
    "# url = \"https://drive.google.com/u/1/uc?id=1ND85Qa01QNNirv9NxLS_L90O3mTBpaX6&export=download\"\n",
    "# output = \"cats_dogs.zip\"\n",
    "# gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12c7469",
   "metadata": {
    "id": "a12c7469"
   },
   "source": [
    "## 1. 解壓縮資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4e7bdd",
   "metadata": {
    "executionInfo": {
     "elapsed": 2756,
     "status": "ok",
     "timestamp": 1742277491583,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "3b4e7bdd"
   },
   "outputs": [],
   "source": [
    "# !unzip -qq cats_dogs.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d05a91a",
   "metadata": {
    "id": "3d05a91a"
   },
   "source": [
    "# 二、實際使用各種learning rate訓練機制來訓練一個貓狗分類模型吧！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caaaec8",
   "metadata": {
    "id": "5caaaec8"
   },
   "source": [
    "## 1. 將訓練集與測試集讀取進來\n",
    "\n",
    "- 主要會將圖片的路徑以及圖片的標籤儲存在陣列裡面\n",
    "    - x_data_list : 陣列，儲存圖片路徑\n",
    "    - y_data_list : 陣列，儲存圖片標籤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc497a4",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1742277509130,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "2cc497a4"
   },
   "outputs": [],
   "source": [
    "image_shape = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47327038",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1742277509139,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "47327038"
   },
   "outputs": [],
   "source": [
    "Trainloc = './dataset/training_set' #訓練集的路徑\n",
    "Testloc = './dataset/test_set'      #測試集的路徑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c48273",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1742277509142,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "47c48273"
   },
   "outputs": [],
   "source": [
    "def DirToDataFrame(data_path):\n",
    "    x_data_list = []\n",
    "    y_data_list = []\n",
    "\n",
    "    for label in os.listdir(data_path):                           #找出第一層的folder，也就是貓還是狗的folder\n",
    "        for img in os.listdir(os.path.join(data_path,label)):     #貓與狗folder裡面的圖片\n",
    "            if img[-4:] == '.jpg':\n",
    "                x_data_list.append(os.path.join(data_path,label,img)) #將圖片路徑儲存在x_data_list\n",
    "                y_data_list.append(label)                             #將標籤儲存在y_data_list\n",
    "\n",
    "    data_list = pd.DataFrame({})\n",
    "    data_list['img_path'] = x_data_list\n",
    "    data_list['label'] = y_data_list\n",
    "    return data_list, x_data_list, y_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b87063d",
   "metadata": {
    "executionInfo": {
     "elapsed": 78,
     "status": "ok",
     "timestamp": 1742277509220,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "9b87063d"
   },
   "outputs": [],
   "source": [
    "Traindf, Train_img, Train_label = DirToDataFrame(Trainloc)\n",
    "Testdf, Test_img, Test_label = DirToDataFrame(Testloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3756f2e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1742277509224,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "3756f2e8",
    "outputId": "a2dcef0a-5a43-472d-b6d3-5e929efe6cc0"
   },
   "outputs": [],
   "source": [
    "# print(Traindf.groupby('label').size().sort_values())\n",
    "# print(Testdf.groupby('label').size().sort_values())\n",
    "print(Traindf.groupby('label').size())\n",
    "print(Testdf.groupby('label').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65937ad5",
   "metadata": {
    "id": "65937ad5"
   },
   "source": [
    "## 2. 標籤的Number Encoding\n",
    "\n",
    "在模型中，需要將標籤轉換成數字才能做訓練，以`dog`與`cat`為例，需要將其轉換成0以及1。\n",
    "\n",
    "所以我們建立一個字典，如：{'dogs': 0, 'cats': 1}，讓他可以在data loader中作轉換。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ef6ce7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 224,
     "status": "ok",
     "timestamp": 1742277509447,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "f2ef6ce7",
    "outputId": "8bcf35f8-c597-45f5-d354-b044bd4d3e33"
   },
   "outputs": [],
   "source": [
    "label_dict = {}\n",
    "\n",
    "Count = 0\n",
    "for i in range(len(Traindf)):\n",
    "    if Traindf.iloc[i].label in label_dict:\n",
    "        continue\n",
    "    else:\n",
    "        label_dict[Traindf.iloc[i].label] = Count\n",
    "        Count += 1\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43658309",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1742277509491,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "43658309",
    "outputId": "bad89d9e-bf5d-448f-c716-febed65b06d6"
   },
   "outputs": [],
   "source": [
    "labelreverse = {v: k for k, v in label_dict.items()}\n",
    "labelreverse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48db7621",
   "metadata": {
    "id": "48db7621"
   },
   "source": [
    "## 3. 建立預處理功能以及建立data loader\n",
    "\n",
    "有一個很大的重點，訓練集可以做資料預處理及各式各樣的資料擴增，但驗證或是測試集僅能做資料預處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ba2301",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1742277509492,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "23ba2301"
   },
   "outputs": [],
   "source": [
    "# 訓練集的預處理及資料擴增\n",
    "# resize的default為PIL.Image.BILINEAR\n",
    "preprocess_train = transforms.Compose([transforms.ToTensor(),\n",
    "                                       transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                       transforms.Resize((image_shape,image_shape))])\n",
    "                                       #transforms.RandomResizedCrop((image_shape,image_shape))])\n",
    "\n",
    "# 測試集的預處理\n",
    "preprocess_test = transforms.Compose([transforms.ToTensor(),\n",
    "                                      transforms.Resize((image_shape,image_shape))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a4364a",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1742277509492,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "a4a4364a"
   },
   "outputs": [],
   "source": [
    "def default_loader(path, preprocess_function):\n",
    "    # 使用cv2讀取圖片\n",
    "    img_pil = cv2.imread(path)\n",
    "    # 將BGR 轉換成 RGB\n",
    "    img_pil = cv2.cvtColor(img_pil, cv2.COLOR_BGR2RGB)\n",
    "    # 將前面的預處理方式加入圖片中\n",
    "    img_tensor = preprocess_function(img_pil)\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7bb660",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1742277509493,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "8c7bb660"
   },
   "outputs": [],
   "source": [
    "class Custom_Generator(Dataset):\n",
    "    def __init__(self, image_file, image_label, label_dict, pre_fn, loader = default_loader):\n",
    "\n",
    "        self.images = image_file      # 圖片路徑的陣列\n",
    "        self.target = image_label     # 圖片標籤的陣列\n",
    "        self.label_dict = label_dict  # 如：{'dogs': 0, 'cats': 1}\n",
    "        self.pre_fn = pre_fn          # 資料預處理\n",
    "        self.loader = loader          # 讀圖片的function\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fn = self.images[index]      # 圖片路徑\n",
    "\n",
    "        img = self.loader(path = fn, # 圖片讀取以及預處理後的結果，輸入模型用\n",
    "                          preprocess_function = self.pre_fn)\n",
    "\n",
    "        target = self.label_dict[self.target[index]] # 圖片標籤, 並轉換成數字\n",
    "\n",
    "        return img,target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)     # 回傳資料集數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366d7d08",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1742279699551,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "366d7d08",
    "outputId": "c39e9314-6979-4128-bafb-2948a165398a"
   },
   "outputs": [],
   "source": [
    "# 1. 先呼叫我們寫好的Custom_Generator, 將圖片的路徑陣列、圖片的標籤陣列以及預處理功能放入裡面\n",
    "train_data  = Custom_Generator(image_file = Train_img,\n",
    "                               image_label = Train_label,\n",
    "                               label_dict = label_dict,\n",
    "                               pre_fn = preprocess_train)\n",
    "\n",
    "# 2. 呼叫pytorch的DataLoader來做批次動作，模型的輸入\n",
    "# num_workers : 表示開啟多少個線程數去加載你的數據，默認為0，代表只使用主進程。\n",
    "# pin_memory : 表示要將load進來的數據是否要拷貝到pin_memory區中，其表示生成的Tensor數據是屬於內存中的鎖頁內存區，這樣將Tensor數據轉義到GPU中速度就會快一些，默認為False。\n",
    "trainloader = DataLoader(train_data, batch_size=32,shuffle=True, num_workers = 3, pin_memory = True,persistent_workers=True)\n",
    "\n",
    "# 1. 先呼叫我們寫好的Custom_Generator, 將圖片的路徑陣列、圖片的標籤陣列以及預處理功能放入裡面\n",
    "test_data  = Custom_Generator(image_file = Test_img,\n",
    "                              image_label = Test_label,\n",
    "                              label_dict = label_dict,\n",
    "                              pre_fn = preprocess_test)\n",
    "\n",
    "# 2. 呼叫pytorch的DataLoader來做批次動作，模型的輸入\n",
    "testloader = DataLoader(test_data, batch_size=32,shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5d333e",
   "metadata": {
    "id": "ef5d333e"
   },
   "source": [
    "## 4. 查看訓練集圖片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1887fe3",
   "metadata": {
    "executionInfo": {
     "elapsed": 784,
     "status": "ok",
     "timestamp": 1742277510277,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "e1887fe3"
   },
   "outputs": [],
   "source": [
    "train_dataiter = iter(trainloader)   #迭代器\n",
    "images,labels = next(train_dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d435f695",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "129x-20uKud4UW0A_FkN-yz9fhOQkAxwC"
    },
    "executionInfo": {
     "elapsed": 5633,
     "status": "ok",
     "timestamp": 1742277515916,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "d435f695",
    "outputId": "17bb9c02-2ba3-4180-cf69-0139996af090"
   },
   "outputs": [],
   "source": [
    "plt.gcf().set_size_inches(20, 20) # gcf => get current figure\n",
    "\n",
    "for i in range(images.shape[0]):\n",
    "    img_show = plt.subplot(6, 6, i+1)\n",
    "    plt.imshow(np.transpose(images[i],(1,2,0)))\n",
    "    plt.title(labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f0e2ff",
   "metadata": {
    "id": "b1f0e2ff"
   },
   "source": [
    "## 5. 建立一個簡單的分類模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0ebed7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1742277515928,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "8c0ebed7",
    "outputId": "7f6f9ac4-d639-45eb-d1b2-82aad0edf278"
   },
   "outputs": [],
   "source": [
    "conv_list = [32,32,\"DS\",64,64,\"DS\"]\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, conv_list):\n",
    "        super(Model,self).__init__()\n",
    "\n",
    "        self.out_size = input_size // 4\n",
    "        self.conv_list = conv_list\n",
    "        self.CNN_Feature = self.conv_block()\n",
    "        self.fc = nn.Sequential(nn.Linear(in_features = 64*self.out_size*self.out_size, out_features = 128),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Linear(in_features = 128, out_features = 2))\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def conv_block(self):\n",
    "        layers = []\n",
    "        in_channel = 3\n",
    "\n",
    "        for channel in self.conv_list:\n",
    "            if channel == 'DS':\n",
    "                layers.append(nn.MaxPool2d(2,2))\n",
    "\n",
    "            else:\n",
    "                layers.append(nn.Conv2d(in_channel, channel, kernel_size = 3, padding = 1))\n",
    "                layers.append(nn.ReLU(inplace=True))\n",
    "                # 下一次的輸入channel = 現在的輸出channel\n",
    "                in_channel = channel\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = self.CNN_Feature(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = Model(input_size = 128, conv_list = conv_list).to(device)\n",
    "summary(model, input_size=(3, 128, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54a785f",
   "metadata": {
    "id": "b54a785f"
   },
   "source": [
    "# 固定learning rate訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dd609c",
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1742277515929,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "78dd609c"
   },
   "outputs": [],
   "source": [
    "# 超參數設定\n",
    "# criterion : loss function\n",
    "# lr : learning rate\n",
    "# epochs : epoch 數量\n",
    "# optimizer : 優化器\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.001\n",
    "epochs = 20\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3b6cef",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1742277515931,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "2b3b6cef"
   },
   "outputs": [],
   "source": [
    "def PrintLogMessage(Now_epoch, Total_epoch, Now_itr, Total_itr, loss, acc, train = True, flush = False):\n",
    "    if train == True and flush == True:\n",
    "        print('[%02d/%02d, %d/%d] loss: %.3f, acc: %.3f' % (Now_epoch, Total_epoch, Now_itr, Total_itr, loss,acc),end = \"\")\n",
    "        print(\"\\r\", end=\"\", flush=True)\n",
    "    elif train == True and flush == False:\n",
    "        print('[%02d/%02d, %d/%d] loss: %.3f, acc: %.3f' % (Now_epoch, Total_epoch, Now_itr, Total_itr, loss,acc),end = \"\")\n",
    "    elif train == False:\n",
    "        print(', test_loss: %.3f, test_acc: %.3f' % (loss,acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07bc111",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 692958,
     "status": "ok",
     "timestamp": 1742278208889,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "a07bc111",
    "outputId": "c284711e-bb5d-402e-9939-e25263ea13a6"
   },
   "outputs": [],
   "source": [
    "# 訓練過程\n",
    "\n",
    "fixed_lr_train_acc = []\n",
    "fixed_lr_train_loss = []\n",
    "fixed_lr_test_acc = []\n",
    "fixed_lr_test_loss = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 訓練階段\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    for times, data_train in enumerate(trainloader, 0):\n",
    "        # batch data input\n",
    "        inputs, labels = data_train\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # model Feedforward\n",
    "        output_train = model(inputs)\n",
    "        # Feed forward loss result\n",
    "        loss = criterion(output_train, labels)\n",
    "\n",
    "        # backward update\n",
    "        loss.backward()\n",
    "\n",
    "        # optimize\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(output_train.data, 1)\n",
    "        total += labels.size(0)\n",
    "        accuracy += (predicted == labels).sum().item()\n",
    "        # Print log message\n",
    "        PrintLogMessage(Now_epoch = epoch+1,\n",
    "                        Total_epoch = epochs,\n",
    "                        Now_itr = times+1,\n",
    "                        Total_itr = len(trainloader),\n",
    "                        loss = running_loss/(times+1),\n",
    "                        acc = accuracy / total,\n",
    "                        train = True,\n",
    "                        flush = True)\n",
    "        if times+1 == len(trainloader):\n",
    "            # Print log message\n",
    "            PrintLogMessage(Now_epoch = epoch+1,\n",
    "                            Total_epoch = epochs,\n",
    "                            Now_itr = times+1,\n",
    "                            Total_itr = len(trainloader),\n",
    "                            loss = running_loss/len(trainloader),\n",
    "                            acc = accuracy / total,\n",
    "                            train = True,\n",
    "                            flush = False)\n",
    "\n",
    "            fixed_lr_train_acc.append(accuracy / total)\n",
    "            fixed_lr_train_loss.append(running_loss/len(trainloader))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # 測試階段\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    with torch.no_grad(): # disable gradient calculation for efficiency\n",
    "        for times, data_test in enumerate(testloader, 0):\n",
    "            # batch data input\n",
    "            inputs, labels = data_test\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # model predict\n",
    "            output_test = model(inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss_t = criterion(output_test, labels)\n",
    "            test_loss += loss_t.item()\n",
    "\n",
    "            # Compute accuracy\n",
    "            _, predicted = torch.max(output_test.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "\n",
    "            if times+1 == len(testloader):\n",
    "                PrintLogMessage(Now_epoch = epoch+1,\n",
    "                                Total_epoch = epochs,\n",
    "                                Now_itr = times+1,\n",
    "                                Total_itr = len(testloader),\n",
    "                                loss = test_loss / len(testloader),\n",
    "                                acc = accuracy / total,\n",
    "                                train = False,)\n",
    "                fixed_lr_test_acc.append(accuracy / total)\n",
    "                fixed_lr_test_loss.append(test_loss/len(testloader))\n",
    "                test_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e30e3a5",
   "metadata": {
    "id": "4e30e3a5"
   },
   "source": [
    "# 使用learning rate step LR 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc99223f",
   "metadata": {
    "executionInfo": {
     "elapsed": 79,
     "status": "ok",
     "timestamp": 1742278208967,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "dc99223f"
   },
   "outputs": [],
   "source": [
    "model = Model(input_size = 128, conv_list = conv_list).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb87293",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1742278208979,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "adb87293",
    "outputId": "b9f50bf1-b294-47b2-f34a-a2acafee7aef"
   },
   "outputs": [],
   "source": [
    "# 超參數設定\n",
    "# cutmix_prob : 使用cutmix的機率\n",
    "# criterion : loss function\n",
    "# lr : learning rate\n",
    "# epochs : epoch 數量\n",
    "# optimizer : 優化器\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.001\n",
    "epochs = 20\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "# 在這邊我們會多一個scheduler來決定怎麼隨著訓練的過程調整optimizer的設定\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma=0.5,verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acd46c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 684306,
     "status": "ok",
     "timestamp": 1742278893286,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "6acd46c2",
    "outputId": "2a7a95f5-6fa8-44c0-c748-f5301f8663cc"
   },
   "outputs": [],
   "source": [
    "# 訓練過程\n",
    "\n",
    "step_lr_train_acc = []\n",
    "step_lr_train_loss = []\n",
    "step_lr_test_acc = []\n",
    "step_lr_test_loss = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 訓練階段\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    for times, data_train in enumerate(trainloader, 0):\n",
    "        # batch data input\n",
    "        inputs, labels = data_train\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # model Feedforward\n",
    "        output_train = model(inputs)\n",
    "        # Feed forward loss result\n",
    "        loss = criterion(output_train, labels)\n",
    "\n",
    "        # backward update\n",
    "        loss.backward()\n",
    "        # optimize\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(output_train.data, 1)\n",
    "        total += labels.size(0)\n",
    "        accuracy += (predicted == labels).sum().item()\n",
    "        # Print log message\n",
    "        PrintLogMessage(Now_epoch = epoch+1,\n",
    "                        Total_epoch = epochs,\n",
    "                        Now_itr = times+1,\n",
    "                        Total_itr = len(trainloader),\n",
    "                        loss = running_loss/(times+1),\n",
    "                        acc = accuracy / total,\n",
    "                        train = True,\n",
    "                        flush = True)\n",
    "        if times+1 == len(trainloader):\n",
    "            # Print log message\n",
    "            PrintLogMessage(Now_epoch = epoch+1,\n",
    "                            Total_epoch = epochs,\n",
    "                            Now_itr = times+1,\n",
    "                            Total_itr = len(trainloader),\n",
    "                            loss = running_loss/len(trainloader),\n",
    "                            acc = accuracy / total,\n",
    "                            train = True,\n",
    "                            flush = False)\n",
    "            step_lr_train_acc.append(accuracy / total)\n",
    "            step_lr_train_loss.append(running_loss/len(trainloader))\n",
    "            running_loss = 0.0\n",
    "    #Scheduler更新Learning Rate\n",
    "    scheduler.step()\n",
    " \n",
    "\n",
    "    # 測試階段\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    with torch.no_grad(): # disable gradient calculation for efficiency\n",
    "        for times, data_test in enumerate(testloader, 0):\n",
    "            # batch data input\n",
    "            inputs, labels = data_test\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # model predict\n",
    "            output_test = model(inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss_t = criterion(output_test, labels)\n",
    "            test_loss += loss_t.item()\n",
    "\n",
    "            # Compute accuracy\n",
    "            _, predicted = torch.max(output_test.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "\n",
    "            if times+1 == len(testloader):\n",
    "                PrintLogMessage(Now_epoch = epoch+1,\n",
    "                                Total_epoch = epochs,\n",
    "                                Now_itr = times+1,\n",
    "                                Total_itr = len(testloader),\n",
    "                                loss = test_loss / len(testloader),\n",
    "                                acc = accuracy / total,\n",
    "                                train = False,)\n",
    "                step_lr_test_acc.append(accuracy / total)\n",
    "                step_lr_test_loss.append(test_loss/len(testloader))\n",
    "                test_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabbed8c",
   "metadata": {
    "id": "cabbed8c"
   },
   "source": [
    "# 使用 ReduceLROnPlateau decay訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca2df0d",
   "metadata": {
    "executionInfo": {
     "elapsed": 77,
     "status": "ok",
     "timestamp": 1742279712938,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "2ca2df0d"
   },
   "outputs": [],
   "source": [
    "model = Model(input_size = 128, conv_list = conv_list).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2157ff7f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1742279713858,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "2157ff7f",
    "outputId": "5d388470-7854-4a35-aa53-bc2b987795cb"
   },
   "outputs": [],
   "source": [
    "# Reduce learning rate\n",
    "# 選用Adam為optimizer\n",
    "# Parameters\n",
    "# pytorch的CrossEntropyLoss在計算時，會以softmax的輸出作為最後的結果\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.001\n",
    "epochs = 20\n",
    "#optimizer_cnn = optim.SGD(cnn_model.parameters(), lr=lr, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f53866",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 704113,
     "status": "ok",
     "timestamp": 1742280419688,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "c4f53866",
    "outputId": "d68a56b9-1d32-4717-c7eb-a8ce2cc95e87"
   },
   "outputs": [],
   "source": [
    "# 訓練過程\n",
    "\n",
    "Reduce_lr_plateau_train_acc = []\n",
    "Reduce_lr_plateau_train_loss = []\n",
    "Reduce_lr_plateau_test_acc = []\n",
    "Reduce_lr_plateau_test_loss = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 訓練階段\n",
    "    model.train() \n",
    "    running_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    for times, data_train in enumerate(trainloader, 0):\n",
    "        # batch data input\n",
    "        inputs, labels = data_train\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # model Feedforward\n",
    "        output_train = model(inputs)\n",
    "        # Feed forward loss result\n",
    "        loss = criterion(output_train, labels)\n",
    "\n",
    "        # backward update\n",
    "        loss.backward()\n",
    "        # optimize\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(output_train.data, 1)\n",
    "        total += labels.size(0)\n",
    "        accuracy += (predicted == labels).sum().item()\n",
    "        # Print log message\n",
    "        PrintLogMessage(Now_epoch = epoch+1,\n",
    "                        Total_epoch = epochs,\n",
    "                        Now_itr = times+1,\n",
    "                        Total_itr = len(trainloader),\n",
    "                        loss = running_loss/(times+1),\n",
    "                        acc = accuracy / total,\n",
    "                        train = True,\n",
    "                        flush = True)\n",
    "        if times+1 == len(trainloader):\n",
    "            # Print log message\n",
    "            PrintLogMessage(Now_epoch = epoch+1,\n",
    "                            Total_epoch = epochs,\n",
    "                            Now_itr = times+1,\n",
    "                            Total_itr = len(trainloader),\n",
    "                            loss = running_loss/len(trainloader),\n",
    "                            acc = accuracy / total,\n",
    "                            train = True,\n",
    "                            flush = False)\n",
    "            Reduce_lr_plateau_train_acc.append(accuracy / total)\n",
    "            Reduce_lr_plateau_train_loss.append(running_loss/len(trainloader))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # 測試階段\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    with torch.no_grad(): # disable gradient calculation for efficiency\n",
    "        for times, data_test in enumerate(testloader, 0):\n",
    "            # batch data input\n",
    "            inputs, labels = data_test\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # model predict\n",
    "            output_test = model(inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss_t = criterion(output_test, labels)\n",
    "            test_loss += loss_t.item()\n",
    "\n",
    "            # Compute accuracy\n",
    "            _, predicted = torch.max(output_test.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "\n",
    "            if times+1 == len(testloader):\n",
    "                #Scheduler更新Learning Rate\n",
    "                scheduler.step(test_loss / len(testloader))\n",
    "                PrintLogMessage(Now_epoch = epoch+1,\n",
    "                                Total_epoch = epochs,\n",
    "                                Now_itr = times+1,\n",
    "                                Total_itr = len(testloader),\n",
    "                                loss = test_loss / len(testloader),\n",
    "                                acc = accuracy / total,\n",
    "                                train = False,)\n",
    "                Reduce_lr_plateau_test_acc.append(accuracy / total)\n",
    "                Reduce_lr_plateau_test_loss.append(test_loss/len(testloader))\n",
    "                test_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a69575",
   "metadata": {
    "id": "79a69575"
   },
   "source": [
    "# Cosine learning rate with warm up 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddDOezFjAZ8J",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1742280454497,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "ddDOezFjAZ8J"
   },
   "outputs": [],
   "source": [
    "# !pip install torchtoolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f6a5ba",
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1742280456435,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "a8f6a5ba"
   },
   "outputs": [],
   "source": [
    "from torchtoolbox.optimizer import CosineWarmupLr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9b7b9e",
   "metadata": {
    "executionInfo": {
     "elapsed": 81,
     "status": "ok",
     "timestamp": 1742280460571,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "1b9b7b9e"
   },
   "outputs": [],
   "source": [
    "model = Model(input_size = 128, conv_list = conv_list).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2ec3d1",
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1742280461250,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "fc2ec3d1"
   },
   "outputs": [],
   "source": [
    "# 超參數設定\n",
    "# criterion : loss function\n",
    "# lr : learning rate\n",
    "# epochs : epoch 數量\n",
    "# optimizer : 優化器\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.001\n",
    "epochs = 20\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "scheduler = CosineWarmupLr(optimizer, len(trainloader), epochs = epochs, base_lr=lr, warmup_epochs=epochs*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693d541a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 714025,
     "status": "ok",
     "timestamp": 1742281176732,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "693d541a",
    "outputId": "94f58431-9505-4122-aa32-ac4637d3f18b"
   },
   "outputs": [],
   "source": [
    "# 訓練過程\n",
    "# len(trainLoader) : 訓練集總共的資料量 / batch\n",
    "# len(trainLoader.dataset) : 訓練集總共的資料量\n",
    "\n",
    "cosinewarmup_train_acc = []\n",
    "cosinewarmup_train_loss = []\n",
    "cosinewarmup_test_acc = []\n",
    "cosinewarmup_test_loss = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 訓練階段\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    for times, data_train in enumerate(trainloader, 0):\n",
    "        # batch data input\n",
    "        inputs, labels = data_train\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # model Feedforward\n",
    "        output_train = model(inputs)\n",
    "        # Feed forward loss result\n",
    "        loss = criterion(output_train, labels)\n",
    "\n",
    "        # backward update\n",
    "        loss.backward()\n",
    "        # optimize\n",
    "        optimizer.step()\n",
    "        #Scheduler更新Learning Rate\n",
    "        scheduler.step()\n",
    "        # Compute loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(output_train.data, 1)\n",
    "        total += labels.size(0)\n",
    "        accuracy += (predicted == labels).sum().item()\n",
    "        # Print log message\n",
    "        PrintLogMessage(Now_epoch = epoch+1,\n",
    "                        Total_epoch = epochs,\n",
    "                        Now_itr = times+1,\n",
    "                        Total_itr = len(trainloader),\n",
    "                        loss = running_loss/(times+1),\n",
    "                        acc = accuracy / total,\n",
    "                        train = True,\n",
    "                        flush = True)\n",
    "        if times+1 == len(trainloader):\n",
    "            # Print log message\n",
    "            PrintLogMessage(Now_epoch = epoch+1,\n",
    "                            Total_epoch = epochs,\n",
    "                            Now_itr = times+1,\n",
    "                            Total_itr = len(trainloader),\n",
    "                            loss = running_loss/len(trainloader),\n",
    "                            acc = accuracy / total,\n",
    "                            train = True,\n",
    "                            flush = False)\n",
    "            cosinewarmup_train_acc.append(accuracy / total)\n",
    "            cosinewarmup_train_loss.append(running_loss/len(trainloader))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # 測試階段\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    with torch.no_grad(): # disable gradient calculation for efficiency\n",
    "        for times, data_test in enumerate(testloader, 0):\n",
    "            # batch data input\n",
    "            inputs, labels = data_test\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # model predict\n",
    "            output_test = model(inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss_t = criterion(output_test, labels)\n",
    "            test_loss += loss_t.item()\n",
    "\n",
    "            # Compute accuracy\n",
    "            _, predicted = torch.max(output_test.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "\n",
    "            if times+1 == len(testloader):\n",
    "                PrintLogMessage(Now_epoch = epoch+1,\n",
    "                                Total_epoch = epochs,\n",
    "                                Now_itr = times+1,\n",
    "                                Total_itr = len(testloader),\n",
    "                                loss = test_loss / len(testloader),\n",
    "                                acc = accuracy / total,\n",
    "                                train = False,)\n",
    "                cosinewarmup_test_acc.append(accuracy / total)\n",
    "                cosinewarmup_test_loss.append(test_loss/len(testloader))\n",
    "                test_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6902d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 854,
     "status": "ok",
     "timestamp": 1742281177588,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "af6902d6",
    "outputId": "d94c86d0-babb-457f-8029-2f0a37ce83d0"
   },
   "outputs": [],
   "source": [
    "def Show_Train_flow( ResultA,  ResultB, ResultC, ResultD, Show='loss', Title='Training metric comparison'):\n",
    "    plt.plot(ResultA)\n",
    "    plt.plot(ResultB)\n",
    "    plt.plot(ResultC)\n",
    "    plt.plot(ResultD)\n",
    "    plt.title(Title)\n",
    "    plt.ylabel(Show)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Fixed', 'Step', 'Reduce on Plateau', 'Cosine Warm Up '])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "Show_Train_flow( fixed_lr_train_acc, step_lr_train_acc, Reduce_lr_plateau_train_acc, cosinewarmup_train_acc, Show = 'train acc', Title='training acc comparision')\n",
    "Show_Train_flow(fixed_lr_test_acc, step_lr_test_acc, Reduce_lr_plateau_test_acc, cosinewarmup_test_acc,Show = 'test acc', Title='testing acc comparision')\n",
    "\n",
    "Show_Train_flow(fixed_lr_train_loss, step_lr_train_loss, Reduce_lr_plateau_train_loss, cosinewarmup_train_loss,Show = 'train loss', Title='training loss comparision')\n",
    "Show_Train_flow(fixed_lr_test_loss, step_lr_test_loss, Reduce_lr_plateau_test_loss, cosinewarmup_test_loss,Show = 'testing loss', Title='testing loss comparision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001f1285",
   "metadata": {
    "executionInfo": {
     "elapsed": 2082406,
     "status": "aborted",
     "timestamp": 1742279591393,
     "user": {
      "displayName": "Michael Chang",
      "userId": "17202199263773585491"
     },
     "user_tz": -480
    },
    "id": "001f1285"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
