{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.CNN_Dogs_Cats.ipynb 說明\n",
    "本 notebook 是一個完整的「貓狗影像分類」深度學習專案範例，主要內容與流程如下：\n",
    "1. **套件與工具載入**：匯入 PyTorch、torchvision、sklearn、PIL、torchinfo 等深度學習與資料處理相關套件，並載入 EarlyStopping 工具。\n",
    "2. **資料下載與解壓縮**：提供下載 cats_dogs.zip 的程式碼（註解掉），並用 zipfile 解壓縮資料集。\n",
    "3. **裝置檢查**：檢查目前可用的運算裝置（GPU、MPS、CPU），並設定 device 變數。\n",
    "4. **標籤與資料收集**：定義貓狗的標籤對應（dog:0, cat:1），並撰寫 collect_data 函數自動收集資料夾下所有圖片路徑與標籤。\n",
    "5. **資料集切分**：使用 train_test_split 將資料分為訓練集與驗證集，並統計各類別數量。\n",
    "6. **資料增強與正規化**：定義影像增強（隨機翻轉、旋轉等）與正規化（resize、toTensor、normalize）流程。\n",
    "7. **自訂 Dataset 與 DataLoader**：建立 Image_dataset 類別，並用 DataLoader 將資料批次化，方便訓練。\n",
    "8. **CNN Block、Inception Block、ResBlock 實作**：定義多種 CNN 卷積區塊，包括基本卷積、Inception 結構、ResNet 殘差結構，並用 markdown 圖示說明結構。\n",
    "9. **模型架構設計**：組合上述區塊，設計一個多層次的 CNN 架構（CnnArchitecture），最後用 GAP（全域平均池化）與全連接層輸出分類結果。\n",
    "10. **模型訓練設定**：設定 optimizer、loss function、early stopping、學習率調整（scheduler）等訓練相關參數。\n",
    "11. **訓練迴圈**：執行多輪訓練與驗證，記錄 loss 與 accuracy，並根據 early stopping 儲存最佳模型。\n",
    "12. **訓練過程視覺化**：用 matplotlib 畫出 loss 與 accuracy 的變化曲線。\n",
    "13. **模型測試與評估**：載入最佳模型，對測試集進行預測，並用 sklearn 計算分類報告（precision, recall, f1-score）。\n",
    "14. **單張圖片預測**：示範如何對單張圖片進行預測並顯示預測結果（貓或狗）。\n",
    "本 notebook 涵蓋資料前處理、模型設計、訓練、驗證、測試與結果視覺化，並實作了多種 CNN 卷積區塊與現代深度學習訓練技巧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "eYmGIeL5DgiC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import numpy as np\n",
    "import zipfile\n",
    "from torchinfo import summary\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorchtools import EarlyStopping #從其他檔案內取得EarlyStop func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "2tYwyVbMEMLT",
    "outputId": "3eb0a489-0baa-4d82-d2cb-da9e0bc3867b"
   },
   "outputs": [],
   "source": [
    "# import gdown\n",
    "\n",
    "# url = \"https://drive.google.com/u/1/uc?id=1ND85Qa01QNNirv9NxLS_L90O3mTBpaX6&export=download\"\n",
    "# output = \"cats_dogs.zip\"\n",
    "# gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#測試是否有使用到GPU\n",
    "\n",
    "# m1 晶片\n",
    "print(torch.backends.mps.is_available())\n",
    "print(torch.backends.mps.is_built())\n",
    "\n",
    "# nvidia 顯卡\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.backends.cuda.is_built())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "_P4btRTjDgiF"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")# 使用mac m1 晶片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using:cpu\n"
     ]
    }
   ],
   "source": [
    "print(f'using:{device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device not found.\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "38LhJ2fADgiF"
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('./cats_dogs.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1696322136987,
     "user": {
      "displayName": "Guffrey Gu",
      "userId": "09202003599580992976"
     },
     "user_tz": -480
    },
    "id": "yayhv2hfdNBP",
    "outputId": "15cf7bbd-e039-464c-f6ef-4b48f59f8f88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'dog', 1: 'cat'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = {'dog':0, 'cat':1}\n",
    "labelreverse = {v: k for k, v in label_dict.items()}\n",
    "labelreverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "FnLvd4fFGN2w"
   },
   "outputs": [],
   "source": [
    "image_ext = ['jpg', 'png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "0KLA_fNoEoEF"
   },
   "outputs": [],
   "source": [
    "def collect_data(folder: str):\n",
    "    all_data = []\n",
    "    all_label = []\n",
    "\n",
    "    for im_cls in os.listdir(\"./dataset/%s\"%folder):\n",
    "        if im_cls == \"dogs\":\n",
    "            for im_path in os.listdir(\"./dataset/%s/dogs/\"%folder):\n",
    "                ext = im_path.split('.')[-1]\n",
    "                if ext in image_ext:\n",
    "                    all_data.append(\"./dataset/%s/dogs/\"%folder+im_path)\n",
    "                    all_label.append(0)\n",
    "        elif im_cls == \"cats\":\n",
    "            for im_path in os.listdir(\"./dataset/%s/cats/\"%folder):\n",
    "                ext = im_path.split('.')[-1]\n",
    "                if ext in image_ext:\n",
    "                    all_data.append(\"./dataset/%s/cats/\"%folder+im_path)\n",
    "                    all_label.append(1)\n",
    "\n",
    "    return all_data, all_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1696322136987,
     "user": {
      "displayName": "Guffrey Gu",
      "userId": "09202003599580992976"
     },
     "user_tz": -480
    },
    "id": "p5UPrBYDHJhT",
    "outputId": "9df1ff85-238e-401e-bc83-f001ce8dddf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data size :  8005\n",
      "All label size :  8005\n"
     ]
    }
   ],
   "source": [
    "all_data, all_label = collect_data(\"training_set\")\n",
    "\n",
    "print('All data size : ', len(all_data))\n",
    "print('All label size : ', len(all_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "AT5c3FuBIGYe"
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(all_data,\n",
    "                                                    all_label,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=all_label,\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1696322136987,
     "user": {
      "displayName": "Guffrey Gu",
      "userId": "09202003599580992976"
     },
     "user_tz": -480
    },
    "id": "cHnyskNyJcVn",
    "outputId": "13029006-45a5-4183-c13c-9af93d4af2c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data Dog count :  3204\n",
      "Train data Cat count :  3200\n",
      "Valid data Dog count :  801\n",
      "Valid data Cat count :  800\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data Dog count : \", y_train.count(0))\n",
    "print(\"Train data Cat count : \", y_train.count(1))\n",
    "print(\"Valid data Dog count : \", y_valid.count(0))\n",
    "print(\"Valid data Cat count : \", y_valid.count(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "XZqoPyjSKnJa"
   },
   "outputs": [],
   "source": [
    "aug = transforms.RandomOrder([\n",
    "    transforms.RandomHorizontalFlip(p=0.3),\n",
    "    # transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=(-10, 10)),\n",
    "    # transforms.GaussianBlur(kernel_size=(5, 5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "HE3rGBr5er9a"
   },
   "outputs": [],
   "source": [
    "norm = transforms.Compose([\n",
    "    transforms.Resize([224, 224]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], #(input - mean) / std, (R, G, B)\n",
    "                         std=[0.229, 0.224, 0.225]) # from imagenet dataset\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "fXZDYS1nKRqF"
   },
   "outputs": [],
   "source": [
    "class Image_dataset(Dataset):\n",
    "    def __init__(self, X_data, y_data, mode):\n",
    "        self.X_data = X_data        # 輸入的訓練資料\n",
    "        self.y_data = y_data        # 輸入訓練資料的標籤\n",
    "        self.mode = mode\n",
    "        self.norm = norm\n",
    "        if mode =='train':\n",
    "            self.augmentation = aug\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_path = self.X_data[index]\n",
    "        image = Image.open(data_path)\n",
    "        image_tensor = self.norm(image)\n",
    "        if self.mode =='train':\n",
    "            image_tensor = self.augmentation(image_tensor)\n",
    "\n",
    "        target = torch.tensor(int(self.y_data[index]), dtype=torch.long) # 新版本不用再做torch.long了\n",
    "\n",
    "        return image_tensor,target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "JGIZXM99LqXj"
   },
   "outputs": [],
   "source": [
    "train_data = Image_dataset(X_train, y_train, mode='train')\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    "    )\n",
    "# Dataloader parameter settings (sampler)\n",
    "# GPU pytorch DDP\n",
    "valid_data = Image_dataset(X_valid, y_valid, mode='valid')\n",
    "valid_loader = DataLoader(\n",
    "    valid_data,\n",
    "    batch_size=64,\n",
    "    shuffle=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1880,
     "status": "ok",
     "timestamp": 1696322138864,
     "user": {
      "displayName": "Guffrey Gu",
      "userId": "09202003599580992976"
     },
     "user_tz": -480
    },
    "id": "1zkiy9plLkNB",
    "outputId": "f094aad5-e360-4cd1-ef78-e02d7d01f492"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)   #迭代器\n",
    "inputs,labels = next(dataiter)\n",
    "\n",
    "print(inputs.size())\n",
    "print(labels.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "9B-Xo4MEwSOS"
   },
   "outputs": [],
   "source": [
    "def activation_func(activation):\n",
    "    return nn.ModuleDict({\n",
    "        'relu': nn.ReLU(inplace=True),\n",
    "        'leaky_relu': nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "        'sigmoid': nn.Sigmoid(),\n",
    "        'prelu': nn.PReLU(),\n",
    "        'softmax': nn.Softmax(dim=1),\n",
    "        'gelu': nn.GELU()})[activation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "N1Fkm-FtwSOS"
   },
   "outputs": [],
   "source": [
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channel, k_size, activation='relu', pad=1, s=1, dilation=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channel,\n",
    "                              k_size, padding=pad, stride=s, dilation=dilation)\n",
    "        self.batchNorm = nn.BatchNorm2d(out_channel)\n",
    "        self.actfunction = activation_func(activation)\n",
    "        self.act_name = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.actfunction(x)\n",
    "        x = self.batchNorm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "P185Ff9xwSOS"
   },
   "outputs": [],
   "source": [
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, Filter_List):\n",
    "        super().__init__()\n",
    "        self.ConvA = nn.Sequential(nn.Conv2d(in_channels=in_channels, out_channels=Filter_List[0], kernel_size=1),\n",
    "                                     nn.ReLU(inplace=True))\n",
    "\n",
    "        self.ConvB = nn.Sequential(nn.Conv2d(in_channels=in_channels, out_channels=Filter_List[1], kernel_size=1),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.Conv2d(in_channels=Filter_List[1], out_channels=Filter_List[2], kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace=True))\n",
    "\n",
    "        self.ConvC = nn.Sequential(nn.Conv2d(in_channels=in_channels, out_channels=Filter_List[3], kernel_size=1),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.Conv2d(in_channels=Filter_List[3], out_channels=Filter_List[4], kernel_size=5, padding=2),\n",
    "                                   nn.ReLU(inplace=True))\n",
    "\n",
    "        self.ConvD = nn.Sequential(nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "                                   nn.Conv2d(in_channels=in_channels, out_channels=Filter_List[5], kernel_size=1),\n",
    "                                   nn.ReLU(inplace=True))\n",
    "    def forward(self, x):\n",
    "        out1 = self.ConvA(x)\n",
    "        out2 = self.ConvB(x)\n",
    "        out3 = self.ConvC(x)\n",
    "        out4 = self.ConvD(x)\n",
    "        out = torch.cat([out1, out2, out3, out4], dim=1) # dim=1是因為用channel在疊\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "```\n",
    "                      +--------------+\n",
    "                      |  Input (x)   |\n",
    "                      +--------------+\n",
    "                             │\n",
    "        ┌────────────────────┼────────────────────┬────────────────────┐\n",
    "        │                    │                    │                    │\n",
    "        ▼                    ▼                    ▼                    ▼\n",
    "   +-----------+        +-------------+      +-------------+      +--------------+\n",
    "   |  ConvA    |        |   ConvB     |      |   ConvC     |      |    ConvD     |\n",
    "   | (1x1 conv)|        | (1x1→3x3)   |      | (1x1→5x5)   |      | (MaxPool→1x1)|\n",
    "   |   ReLU    |        |   ReLU      |      |   ReLU      |      |    ReLU      |\n",
    "   +-----------+        +-------------+      +-------------+      +--------------+\n",
    "        │                    │                    │                    │\n",
    "        └────────────┬───────┴───────┬────────────┴───────┬────────────┘\n",
    "                     │                   │                    │\n",
    "                     ▼                   ▼                    ▼\n",
    "            +-----------------------------------------------+\n",
    "            |  Concatenation along channel dimension (dim=1)|\n",
    "            +-----------------------------------------------+\n",
    "                             │\n",
    "                             ▼\n",
    "                         +----------+\n",
    "                         |  Output  |\n",
    "                         +----------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "VCOt8x_mwSOT"
   },
   "outputs": [],
   "source": [
    "# ResBlock 有兩種，要再去論文內閱讀補充\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, activation='relu'):\n",
    "        super().__init__()\n",
    "        self.convR1 = CNNBlock(in_channels,\n",
    "                               int(in_channels/4),\n",
    "                               1, activation, 0)\n",
    "        self.convR2 = CNNBlock(\n",
    "            int(in_channels/4), int(in_channels/4), 3, activation, 1)\n",
    "        self.convR3 = CNNBlock(\n",
    "            int(in_channels/4), in_channels, 1, activation, 0)\n",
    "        self.actfunctionR = activation_func(activation)\n",
    "# 為什麼channel是除以4？ 原作者實驗下來的結果\n",
    "    def forward(self, x):\n",
    "        x1 = self.convR1(x)\n",
    "        x2 = self.convR2(x1)\n",
    "        x3 = self.convR3(x2)\n",
    "        res = x + x3\n",
    "        res = self.actfunctionR(res)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "         ┌───────────────┐\n",
    "         │  x (原始輸入)  │\n",
    "         └───────────────┘\n",
    "                 │\n",
    "                 │\n",
    "                 ▼\n",
    "         ┌───────────────┐\n",
    "         │CNNBlock convR1│   1×1 卷積 (降維：in_channels → in_channels/4)\n",
    "         └───────────────┘\n",
    "                 │\n",
    "                 ▼\n",
    "         ┌───────────────┐\n",
    "         │CNNBlock convR2│   3×3 卷積 (保持通道數：in_channels/4)\n",
    "         └───────────────┘\n",
    "                 │\n",
    "                 ▼\n",
    "         ┌───────────────┐\n",
    "         │CNNBlock convR3│   1×1 卷積 (升維：in_channels/4 → in_channels)\n",
    "         └───────────────┘\n",
    "                 │\n",
    "                 ├─────────────────────┐\n",
    "                 │                     │\n",
    "                 ▼                     │\n",
    "          ┌───────────────┐            │\n",
    "          │加法 (Residual) │  ◄─────────┘   (將 convR3 的輸出與原始輸入 x 相加)\n",
    "          └───────────────┘\n",
    "                 │\n",
    "                 ▼\n",
    "         ┌───────────────┐\n",
    "         │激活函數 (activation)│   (例如 ReLU)\n",
    "         └───────────────┘\n",
    "                 │\n",
    "                 ▼\n",
    "          ┌───────────────┐\n",
    "          │     Output    │\n",
    "          └───────────────┘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "oooDO9FuOjPm"
   },
   "outputs": [],
   "source": [
    "# Model structure\n",
    "class CnnArchitecture(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CnnArchitecture, self).__init__()\n",
    "\n",
    "        self.cls = 2\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        self.cnn1 = CNNBlock(3, 16, 7, s=2, pad=3)\n",
    "        self.res1 = ResBlock(16)\n",
    "\n",
    "        self.inc = InceptionBlock(16, [64, 96, 128, 16, 32, 32])\n",
    "\n",
    "        self.res2 = ResBlock(256)\n",
    "\n",
    "        self.cnn2 = CNNBlock(256, 512, 1, pad=0)\n",
    "\n",
    "\n",
    "        self.cnn3 = CNNBlock(512, 64, 1, pad=0)\n",
    "        self.res3 = ResBlock(64)\n",
    "\n",
    "        self.cnn4 = CNNBlock(64, 32, 1, pad=0)\n",
    "        self.res4 = ResBlock(32)\n",
    "\n",
    "        self.output = nn.Sequential(nn.Conv2d(in_channels = 32, out_channels = self.cls, kernel_size = 1, padding = 0),\n",
    "                                    nn.AdaptiveAvgPool2d(1),\n",
    "                                    ) # GAP 實作方法 可以提， 新的模型大多使用 GAP取代 Flatten, 神經網路夠深，才會建議使用GAP\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.res1(self.cnn1(x)))\n",
    "        x = self.inc(x)\n",
    "        x = self.res2(x)\n",
    "        x = self.pool(self.cnn2(x))\n",
    "\n",
    "        x = self.pool(self.res3(self.cnn3(x)))\n",
    "        x = self.pool(self.res4(self.cnn4(x)))\n",
    "\n",
    "        x = self.output(x)\n",
    "        x = x.view(-1, self.cls) # input shape(batch, Class_size, 1, 1)\n",
    "\n",
    "        # print(x.size())\n",
    "\n",
    "        return x\n",
    "\n",
    "cnn_model = CnnArchitecture().to(device)\n",
    "# print(cnn_model)\n",
    "\n",
    "test_tensor = torch.randn((1, 3, 224, 224)).to(device)\n",
    "output = cnn_model(test_tensor)\n",
    "# print(output.size())\n",
    "# print(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1696322150914,
     "user": {
      "displayName": "Guffrey Gu",
      "userId": "09202003599580992976"
     },
     "user_tz": -480
    },
    "id": "XBLMxAh7SsNC",
    "outputId": "7fc2703e-019b-4cbd-9326-3a9d765ab75a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CnnArchitecture                          [1, 2]                    --\n",
       "├─CNNBlock: 1-1                          [1, 16, 112, 112]         --\n",
       "│    └─Conv2d: 2-1                       [1, 16, 112, 112]         2,368\n",
       "│    └─ReLU: 2-2                         [1, 16, 112, 112]         --\n",
       "│    └─BatchNorm2d: 2-3                  [1, 16, 112, 112]         32\n",
       "├─ResBlock: 1-2                          [1, 16, 112, 112]         --\n",
       "│    └─CNNBlock: 2-4                     [1, 4, 112, 112]          --\n",
       "│    │    └─Conv2d: 3-1                  [1, 4, 112, 112]          68\n",
       "│    │    └─ReLU: 3-2                    [1, 4, 112, 112]          --\n",
       "│    │    └─BatchNorm2d: 3-3             [1, 4, 112, 112]          8\n",
       "│    └─CNNBlock: 2-5                     [1, 4, 112, 112]          --\n",
       "│    │    └─Conv2d: 3-4                  [1, 4, 112, 112]          148\n",
       "│    │    └─ReLU: 3-5                    [1, 4, 112, 112]          --\n",
       "│    │    └─BatchNorm2d: 3-6             [1, 4, 112, 112]          8\n",
       "│    └─CNNBlock: 2-6                     [1, 16, 112, 112]         --\n",
       "│    │    └─Conv2d: 3-7                  [1, 16, 112, 112]         80\n",
       "│    │    └─ReLU: 3-8                    [1, 16, 112, 112]         --\n",
       "│    │    └─BatchNorm2d: 3-9             [1, 16, 112, 112]         32\n",
       "│    └─ReLU: 2-7                         [1, 16, 112, 112]         --\n",
       "├─MaxPool2d: 1-3                         [1, 16, 56, 56]           --\n",
       "├─InceptionBlock: 1-4                    [1, 256, 56, 56]          --\n",
       "│    └─Sequential: 2-8                   [1, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-10                 [1, 64, 56, 56]           1,088\n",
       "│    │    └─ReLU: 3-11                   [1, 64, 56, 56]           --\n",
       "│    └─Sequential: 2-9                   [1, 128, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-12                 [1, 96, 56, 56]           1,632\n",
       "│    │    └─ReLU: 3-13                   [1, 96, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-14                 [1, 128, 56, 56]          110,720\n",
       "│    │    └─ReLU: 3-15                   [1, 128, 56, 56]          --\n",
       "│    └─Sequential: 2-10                  [1, 32, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-16                 [1, 16, 56, 56]           272\n",
       "│    │    └─ReLU: 3-17                   [1, 16, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-18                 [1, 32, 56, 56]           12,832\n",
       "│    │    └─ReLU: 3-19                   [1, 32, 56, 56]           --\n",
       "│    └─Sequential: 2-11                  [1, 32, 56, 56]           --\n",
       "│    │    └─MaxPool2d: 3-20              [1, 16, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-21                 [1, 32, 56, 56]           544\n",
       "│    │    └─ReLU: 3-22                   [1, 32, 56, 56]           --\n",
       "├─ResBlock: 1-5                          [1, 256, 56, 56]          --\n",
       "│    └─CNNBlock: 2-12                    [1, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-23                 [1, 64, 56, 56]           16,448\n",
       "│    │    └─ReLU: 3-24                   [1, 64, 56, 56]           --\n",
       "│    │    └─BatchNorm2d: 3-25            [1, 64, 56, 56]           128\n",
       "│    └─CNNBlock: 2-13                    [1, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-26                 [1, 64, 56, 56]           36,928\n",
       "│    │    └─ReLU: 3-27                   [1, 64, 56, 56]           --\n",
       "│    │    └─BatchNorm2d: 3-28            [1, 64, 56, 56]           128\n",
       "│    └─CNNBlock: 2-14                    [1, 256, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-29                 [1, 256, 56, 56]          16,640\n",
       "│    │    └─ReLU: 3-30                   [1, 256, 56, 56]          --\n",
       "│    │    └─BatchNorm2d: 3-31            [1, 256, 56, 56]          512\n",
       "│    └─ReLU: 2-15                        [1, 256, 56, 56]          --\n",
       "├─CNNBlock: 1-6                          [1, 512, 56, 56]          --\n",
       "│    └─Conv2d: 2-16                      [1, 512, 56, 56]          131,584\n",
       "│    └─ReLU: 2-17                        [1, 512, 56, 56]          --\n",
       "│    └─BatchNorm2d: 2-18                 [1, 512, 56, 56]          1,024\n",
       "├─MaxPool2d: 1-7                         [1, 512, 28, 28]          --\n",
       "├─CNNBlock: 1-8                          [1, 64, 28, 28]           --\n",
       "│    └─Conv2d: 2-19                      [1, 64, 28, 28]           32,832\n",
       "│    └─ReLU: 2-20                        [1, 64, 28, 28]           --\n",
       "│    └─BatchNorm2d: 2-21                 [1, 64, 28, 28]           128\n",
       "├─ResBlock: 1-9                          [1, 64, 28, 28]           --\n",
       "│    └─CNNBlock: 2-22                    [1, 16, 28, 28]           --\n",
       "│    │    └─Conv2d: 3-32                 [1, 16, 28, 28]           1,040\n",
       "│    │    └─ReLU: 3-33                   [1, 16, 28, 28]           --\n",
       "│    │    └─BatchNorm2d: 3-34            [1, 16, 28, 28]           32\n",
       "│    └─CNNBlock: 2-23                    [1, 16, 28, 28]           --\n",
       "│    │    └─Conv2d: 3-35                 [1, 16, 28, 28]           2,320\n",
       "│    │    └─ReLU: 3-36                   [1, 16, 28, 28]           --\n",
       "│    │    └─BatchNorm2d: 3-37            [1, 16, 28, 28]           32\n",
       "│    └─CNNBlock: 2-24                    [1, 64, 28, 28]           --\n",
       "│    │    └─Conv2d: 3-38                 [1, 64, 28, 28]           1,088\n",
       "│    │    └─ReLU: 3-39                   [1, 64, 28, 28]           --\n",
       "│    │    └─BatchNorm2d: 3-40            [1, 64, 28, 28]           128\n",
       "│    └─ReLU: 2-25                        [1, 64, 28, 28]           --\n",
       "├─MaxPool2d: 1-10                        [1, 64, 14, 14]           --\n",
       "├─CNNBlock: 1-11                         [1, 32, 14, 14]           --\n",
       "│    └─Conv2d: 2-26                      [1, 32, 14, 14]           2,080\n",
       "│    └─ReLU: 2-27                        [1, 32, 14, 14]           --\n",
       "│    └─BatchNorm2d: 2-28                 [1, 32, 14, 14]           64\n",
       "├─ResBlock: 1-12                         [1, 32, 14, 14]           --\n",
       "│    └─CNNBlock: 2-29                    [1, 8, 14, 14]            --\n",
       "│    │    └─Conv2d: 3-41                 [1, 8, 14, 14]            264\n",
       "│    │    └─ReLU: 3-42                   [1, 8, 14, 14]            --\n",
       "│    │    └─BatchNorm2d: 3-43            [1, 8, 14, 14]            16\n",
       "│    └─CNNBlock: 2-30                    [1, 8, 14, 14]            --\n",
       "│    │    └─Conv2d: 3-44                 [1, 8, 14, 14]            584\n",
       "│    │    └─ReLU: 3-45                   [1, 8, 14, 14]            --\n",
       "│    │    └─BatchNorm2d: 3-46            [1, 8, 14, 14]            16\n",
       "│    └─CNNBlock: 2-31                    [1, 32, 14, 14]           --\n",
       "│    │    └─Conv2d: 3-47                 [1, 32, 14, 14]           288\n",
       "│    │    └─ReLU: 3-48                   [1, 32, 14, 14]           --\n",
       "│    │    └─BatchNorm2d: 3-49            [1, 32, 14, 14]           64\n",
       "│    └─ReLU: 2-32                        [1, 32, 14, 14]           --\n",
       "├─MaxPool2d: 1-13                        [1, 32, 7, 7]             --\n",
       "├─Sequential: 1-14                       [1, 2, 1, 1]              --\n",
       "│    └─Conv2d: 2-33                      [1, 2, 7, 7]              66\n",
       "│    └─AdaptiveAvgPool2d: 2-34           [1, 2, 1, 1]              --\n",
       "==========================================================================================\n",
       "Total params: 374,266\n",
       "Trainable params: 374,266\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 1.09\n",
       "==========================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 64.48\n",
       "Params size (MB): 1.50\n",
       "Estimated Total Size (MB): 66.58\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(cnn_model, input_data=test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "9L0EPZrfPEcv"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(cnn_model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "crnKZJYSU22p"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=5,\n",
    "                               verbose=True,\n",
    "                               path=\"save_model/best_weights.pth\",\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "4fYKSQebU7Lb"
   },
   "outputs": [],
   "source": [
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "#                                                        mode='min',\n",
    "#                                                        factor=0.1,\n",
    "#                                                        patience=3,\n",
    "#                                                        verbose=True)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "# Warmup-Dicay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "TWZpVeVSW-N6"
   },
   "outputs": [],
   "source": [
    "os.makedirs('save_model', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 496683,
     "status": "ok",
     "timestamp": 1696322647594,
     "user": {
      "displayName": "Guffrey Gu",
      "userId": "09202003599580992976"
     },
     "user_tz": -480
    },
    "id": "7u_V1Qz5DgiH",
    "outputId": "317cc295-1fff-4d1b-da87-a02ffafaae86"
   },
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "i_iter = 0\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "train_accs = []\n",
    "valid_accs = []\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    b_train_loss = []\n",
    "    b_valid_loss = []\n",
    "    b_train_acc = []\n",
    "    b_valid_acc = []\n",
    "    for idx, (imgs, labels) in enumerate(train_loader):\n",
    "        cnn_model.train()\n",
    "        n_correct_train = 0\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn_model(imgs)\n",
    "\n",
    "        train_loss = loss_fn(outputs, labels)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_outputs_label = torch.argmax(outputs, 1)\n",
    "        n_correct_train = len(torch.where(train_outputs_label == labels)[0])/len(labels)\n",
    "\n",
    "\n",
    "        b_train_loss.append(train_loss.item())\n",
    "        b_train_acc.append(n_correct_train)\n",
    "\n",
    "    n_correct_val = 0\n",
    "    n_val_data = 0\n",
    "    cnn_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _idx, (imgs, labels) in enumerate(valid_loader):\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = cnn_model(imgs)\n",
    "            val_loss = loss_fn(outputs, labels)\n",
    "\n",
    "            val_outputs_label = torch.argmax(outputs, 1)\n",
    "            n_correct_val = len(torch.where(val_outputs_label == labels)[0])/len(labels)\n",
    "\n",
    "            b_valid_loss.append(val_loss.item())\n",
    "            b_valid_acc.append(n_correct_val)\n",
    "\n",
    "    ep_train_loss = np.mean(b_train_loss)\n",
    "    ep_vaild_loss = np.mean(b_valid_loss)\n",
    "    ep_train_acc = np.mean(b_train_acc)\n",
    "    ep_valid_acc = np.mean(b_valid_acc)\n",
    "\n",
    "    train_losses.append(ep_train_loss)\n",
    "    valid_losses.append(ep_vaild_loss)\n",
    "    train_accs.append(ep_train_acc)\n",
    "    valid_accs.append(ep_valid_acc)\n",
    "\n",
    "    print(f'{epoch + 1:2d}/{n_epochs:2d} {idx + 1:3d}/{len(train_loader):3d}, \\\n",
    "        train loss: {ep_train_loss:8.5f}, \\\n",
    "        train acc: {ep_train_acc:7.5f}, \\\n",
    "        val loss: {ep_vaild_loss:8.5f}, \\\n",
    "        val acc: {ep_valid_acc:7.5f}')\n",
    "\n",
    "    scheduler.step()\n",
    "    # To check the current learning rate\n",
    "    print(\"Current learning rate:\", scheduler.get_last_lr())\n",
    "\n",
    "    early_stopping(ep_vaild_loss, cnn_model) # __call__ function\n",
    "    i_iter += 1\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"[INFO] Early stopping\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1696322647595,
     "user": {
      "displayName": "Guffrey Gu",
      "userId": "09202003599580992976"
     },
     "user_tz": -480
    },
    "id": "S4ok92GgYS8O",
    "outputId": "912d11c3-a112-4633-aae5-1f9b6fdb8926"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 視覺化訓練過程\n",
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "# 繪製 Training loss 和 Validation loss\n",
    "plt.subplot(121)\n",
    "plt.plot(range(len(train_losses)), train_losses, label='Training Loss')\n",
    "plt.plot(range(len(valid_losses)), valid_losses, label='Validation Loss')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Loss')\n",
    "\n",
    "# 繪製 Training accuracy 和 Validation accuracy\n",
    "plt.subplot(122)\n",
    "plt.plot(range(len(train_accs)), train_accs, label='Training Accuracy')\n",
    "plt.plot(range(len(valid_accs)), valid_accs, label='Validation Accuracy')\n",
    "plt.yticks(np.arange(0.8, 1, 0.05))\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4478,
     "status": "ok",
     "timestamp": 1696322652068,
     "user": {
      "displayName": "Guffrey Gu",
      "userId": "09202003599580992976"
     },
     "user_tz": -480
    },
    "id": "eAYu5kDHcfBp",
    "outputId": "6a49dfe9-445d-42d5-ef7e-aae7a39b0bb4"
   },
   "outputs": [],
   "source": [
    "test_preds = []\n",
    "cnn_model = torch.load(\"save_model/best_weights.pth\")\n",
    "cnn_model.to(device)\n",
    "\n",
    "test_data, test_label = collect_data(\"test_set\")\n",
    "print(\"test image size:\" , len(test_data))\n",
    "for path in test_data:\n",
    "    image = Image.open(path)\n",
    "    image_tensor = norm(image) # 要記得做一樣的前處理！\n",
    "    image_tensor = torch.unsqueeze(image_tensor, dim=0)\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    outputs = cnn_model(image_tensor)\n",
    "    pred = torch.argmax(outputs, 1).item() #.item()\n",
    "    #pred = torch.argmax(outputs, 1).numpy(*, force=False)\n",
    "    test_preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1696322652068,
     "user": {
      "displayName": "Guffrey Gu",
      "userId": "09202003599580992976"
     },
     "user_tz": -480
    },
    "id": "m16PLrIccFJ0",
    "outputId": "29986829-8df7-4f2d-bbf8-499ab9370c00"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "target_names = ['dog', 'cat']\n",
    "print(metrics.classification_report(test_label, test_preds, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 850,
     "status": "ok",
     "timestamp": 1696322723242,
     "user": {
      "displayName": "Guffrey Gu",
      "userId": "09202003599580992976"
     },
     "user_tz": -480
    },
    "id": "pQpT2IrejCTJ",
    "outputId": "ccb0c9b3-2e23-41ff-d6d4-607348142310"
   },
   "outputs": [],
   "source": [
    "image = Image.open(\"./dataset/test_set/cats/cat.4003.jpg\")\n",
    "image_tensor = norm(image)\n",
    "\n",
    "image_tensor = image_tensor.to(device)\n",
    "image_tensor = torch.unsqueeze(image_tensor, dim=0)\n",
    "\n",
    "outputs = cnn_model(image_tensor)\n",
    "pred = torch.argmax(outputs, 1).item()\n",
    "labelreverse[int(pred)]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
